Deep learning (DL) has become the foundation of contemporary Land Cover and Crop Type (LCCT) classification practices, yet its performance largely depends on the availability of large spatial patches (e.g., 512×512 or 256×256 pixels) that offer rich contextual information. However, in practice, obtaining large patches is challenging due to sensor limitations, fragmented landscapes, or limited training samples. At the same time, valuable freely available pixel-point reference data, collected through field surveys or expert interpretation, remain underutilized to train modern DL models because they lack rich contextual information. To address this gap, this study employs a simple yet effective method that centers small image patches on reference sample pixels producing 9×9 pixel inputs. We then, utilizing sentinel-1 and sentinel-2 data as input data, systematicly evaluated the performance of five widely used DL architectures in LCCT classification (U-Net, U-Net++, Res-U-Net++, DeepLabV3+, and DCNN) when trained on these very small patches across a topographically complex region. Our visual and statistical assessment revealed that, U-Net++ achieved the highest classification accuracy, followed closely by DeepLabV3+, whereas the DCNN exhibited the lowest accuracy. We found that mmodels with nested skip connections and enhanced feature reuse exhibited greater robustness to the loss of spatial context and better extraction of fine-scale patterns. This research discusses the limits and potential of DL architectures under small patch-size constraints and offer practical guidance for data-efficient, high-resolution LCCT mapping in data-limited or heterogeneous regions.
